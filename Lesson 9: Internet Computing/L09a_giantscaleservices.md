# Giant Scale Services

![image-20230424010445747](assets/image-20230424010445747.png)





### Lesson Overview

![image-20230424010438501](assets/image-20230424010438501.png)



### Generic Service Model of Giant Scale Services

![image-20230424011438806](assets/image-20230424011438806.png)

![image-20230424010726651](assets/image-20230424010726651.png)

- Server communicates with each other via the communication backplane.
- Each server can handle the server.
- Load manager redirects & balance the client traffic among all the servers.
- Client requests can be handled in parallel as long as there is enough capacity to handle them. 
- Load manager responsible to hide partial failures.



### Clusters as Workhorses

- Number of nodes scaled by 10x to 100x today compared to Circa 2000
- Each node can itself be a SMP
- Computational cluster: 
  - help to control cost & performance
  - independent components -> can change some parts
  - incremental scalability

![image-20230424011044327](assets/image-20230424011044327.png)



### Load Management Choices

- Load management can be done at any of the 7 layers in the OSI model

![image-20230424011059523](assets/image-20230424011059523.png)



### Load Management at Network Level

![image-20230424011643685](assets/image-20230424011643685.png)

![image-20230424011708499](assets/image-20230424011708499.png)

- Clients redirected to different services
- Assumptions: All servers are identical, the data are replicated

- Pros: good load balance 
- Cons: it cannot hide down server nodes



### Load Management at Transport Level

![image-20230424012336178](assets/image-20230424012336178.png)

![image-20230424011831570](assets/image-20230424011831570.png)

- Layer 4 switches / switch-pairs
- Can dynamically isolate down server nodes from outside world
- More intelligence in layer 4 switches
- Load manager can know the device characteristics (e.g. smartphone)
- Data can be partitioned among the servers => If the server that is holding the particular data is down, data loss is possible
  - Replicate for redundancy can help
- Server can communicate with other servers through the communication backplane



### DQ Principle

- Server has all data Df (full data set) for handling any incoming requests
- Q0 = offered load 
- Qc = the completed request

![image-20230424012559977](assets/image-20230424012559977.png)

![image-20230424012606823](assets/image-20230424012606823.png)

![image-20230424012358914](assets/image-20230424012358914.png)

![image-20230424012211451](assets/image-20230424012211451.png)

- DQ is a system constant that is the system capacity, a system limit
- We can increase the Q if we decrease D; or vice versa. 
  - Serve more queries with less data
  - Serve less queries with more data
- We can either sacrifice Q or D
- IOPS (IO operations per second)
- Giant scale -> load is network bound, not IO bound
- **Uptime (MTBF/MTTR)** 
  - MTBF: Mean time between failure
  - MTTR: mean time to repair
  - Uptime = (MTBF-MTTR)/MTBF ~0.9999 (as close to 1 as possible)

â€‹	![image-20230424014312723](assets/image-20230424014312723.png)



### Replication vs Partitioning 

- Replication: 
  - Harvest unchanged, we can redirect the request to another server
  - Yield is lower. Service is unavailable to some users at some time. 
- Partition: 
  - Some service fails: harvest down, some portion of data is unavailable
  - Q unchanged, we can serve the same number of requests, just the data result is not that good. Each query will be serviced, but they will each get a portion of the data. 
- Assume that D is cheap in giant scale services.
- Failures are bound to happen. Choose replication instead of partition => User usually prefers complete data although service is down for a short time. (example, email service)
- However, for searches/web caches, we can have partial data. Harvest is not so important. 

![image-20230424012755264](assets/image-20230424012755264.png)



### Graceful Degradation

![image-20230424015107666](assets/image-20230424015107666.png)

- DQ constant
- When server is saturated, we can choose
  - D fixed, Q decrease
  - D decrease, Q fixed
- Cost based admission control
- Priority or value based admission control
- Reduce data freshness



### Online Solution and Growth

![image-20230424015543466](assets/image-20230424015543466.png)

![image-20230424015222272](assets/image-20230424015222272.png)

